## Causality in foundation models

Current interest in transformers

Recent foundation model benchmarks

Is attention (and large amounts of data) “all you need” to induce reliable biases in your model? (GPT “understands” language well) [@doi:10.1038/d41586-023-02361-7]

What is the mathematical relationship between explicit (e.g. ODE) and implicit (transformers) models?

Latent encodings of explicit prior knowledge (GEARS)

Stefan's comment: newer architectures (self-supervised) do not decode; how important is it for biological insights, particularly compared with scaling? Exploring and explaining the latent space...

- https://scholar.google.de/citations?view_op=view_citation&hl=de&user=soxv0s0AAAAJ&sortby=pubdate&citation_for_view=soxv0s0AAAAJ:2osOgNQ5qMEC (decoder important)
- https://proceedings.neurips.cc/paper_files/paper/2022/hash/87213955efbe48b46586e37bf2f1fe5b-Abstract-Conference.html (decoder not important)
