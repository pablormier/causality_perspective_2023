## Discussion / Conclusion

### Dichotomy of Scaling (data-driven) and Bias Injection (knowledge-driven)

The debate between adopting scaling strategies versus the injection of biases from PK highlights a fundamental tension in modern biomedical research.
The "Bitter Lesson" suggests a preference for general-purpose learning algorithms that scale with computational resources, implicitly learning biases from data.
Conversely, explicitly injecting biases from PK can lead to more specialised and efficient models that can generalise using relatively little training data, but may not scale.
Hybrid models currently represent a promising middle ground, combining the scalability of generalist models with the efficiency and specificity provided by tailored biases.
Researchers often rely on intuition to determine which biases to inject, understanding that while no single model may universally excel (reflecting the "No Free Lunch" theorem), the blend of generalisation through scaling and specialisation through bias injection might provide a robust framework for tackling complex biomedical challenges.
In addition, complex models often pose computational challenges; many models are limited to network sizes of <10 nodes, and feedback loops are often excluded.

### Theoretical Foundations: Interventions and Inductive Biases

Theoretical work emphasises the need for interventions in causal discovery but does not yet address the influence of inductive biases [@doi:10.48550/arXiv.1207.1389].
The number of required interventions might be reduced significantly when complemented with high-quality observational data and appropriate biases, as suggested by neural causal models [@doi:10.48550/arXiv.1910.01075].
However, the precise nature of these biases and their impact remains understudied theoretically as well as empirically.
The comparative effectiveness and theoretical underpinnings of explicit models versus implicit models are particularly understudied.
Foundation models have embraced causal masking as a step towards integrating causality, but this alone may be insufficient.
Empirical studies and more robust theories are needed to understand these dynamics, including the potential existence and validation of causal latent spaces.

### Data Types: Observational vs. Interventional

The choice between training on observational versus interventional data (or a mixture of both) is critical in the development of models.
While large-scale data collection is vital, the type of data collected can significantly influence model performance and the ability to generalise and make accurate causal inferences.
Observational data are more readily available but may lead to confounded or biassed insights.
Interventional data, while more challenging to obtain, provide clearer causal pathways and can greatly enhance the model's understanding of underlying biological processes.
A balanced approach, possibly incorporating both data types, might provide a more nuanced understanding and improve model robustness and interpretability.

### Foundation Models: Architectural Biases and the No Free Lunch Theorems

Foundation models challenge the "No Free Lunch" theorems by suggesting that certain architectural biases, learned from vast amounts of data, can yield generalisable and high-performing models [@doi:10.48550/arXiv.2304.05366].
These biases, and how to transfer them from LLMs to systems biology, necessitate careful evaluation.
As the biomedical field looks to these models for answers, it becomes crucial to develop frameworks that facilitate rapid development and exploration of ideas [@doi:10.1038/s41587-023-01848-y;@doi:10.48550/arXiv.2210.17283].

### Systems Biology and Implicit Causality

Systems biology has always engaged with causal reasoning, aiming to understand the complex mechanisms underlying biological systems.
New methods and models offer the potential to scale this understanding to larger, more complex systems.
The impact of these methods will depend on the successful integration of appropriate algorithms, biases, and data types.
The field stands at a crossroads, determining whether the future of biological modeling will be dominated by the generation of vast datasets for generalist models or by more nuanced, bias-inclusive architectures.
This decision will significantly influence the direction and effectiveness of future research in systems biology.

### Combining Algorithms and Biases with Data Types for Impactful Biological Modeling

While the allure of generalist models trained on extensive datasets is strong, the unique challenges of biomedical research may necessitate a more tailored approach.
Including explicit favourable biases, informed by deep domain knowledge and specific data types (observational or interventional), could lead to breakthroughs in understanding complex biological systems.
The field must explore these possibilities, balancing the drive for large-scale data with the need for precision and specificity, to realise the full potential of modern systems biology.
